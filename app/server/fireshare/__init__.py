import os, sys
import os.path
import ldap
from flask import Flask
from flask_sqlalchemy import SQLAlchemy
from flask_migrate import Migrate
from flask_login import LoginManager
from flask_cors import CORS
from pathlib import Path
import logging
import json
import secrets
from sqlalchemy import event
from sqlalchemy.engine import Engine
from sqlalchemy.pool import NullPool
from sqlite3 import Connection as SQLite3Connection

logger = logging.getLogger('fireshare')
handler = logging.StreamHandler()
handler.setLevel(os.getenv('FS_LOGLEVEL', 'INFO').upper())
formatter = logging.Formatter('%(asctime)s %(levelname)-7s %(module)s.%(funcName)s:%(lineno)d | %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)
logger.setLevel(logging.DEBUG)

# Configure SQLite for better concurrency
@event.listens_for(Engine, "connect")
def set_sqlite_pragma(dbapi_conn, connection_record):
    if isinstance(dbapi_conn, SQLite3Connection):
        cursor = dbapi_conn.cursor()
        
        # Enable WAL mode for better concurrency
        cursor.execute("PRAGMA journal_mode=WAL")
        
        # Set busy timeout to 30 seconds (instead of failing immediately)
        cursor.execute("PRAGMA busy_timeout = 30000")
        
        # Increase cache size (default is 2MB, increase to 64MB)
        cursor.execute("PRAGMA cache_size = -64000")
        
        # Synchronous = NORMAL for better performance (still safe with WAL)
        cursor.execute("PRAGMA synchronous = NORMAL")
        
        # Temp store in memory
        cursor.execute("PRAGMA temp_store = MEMORY")
        
        # Increase mmap size for better read performance
        cursor.execute("PRAGMA mmap_size = 268435456")  # 256MB
        
        # Set page size (must be done before first write)
        cursor.execute("PRAGMA page_size = 4096")
        
        cursor.close()
        
# init SQLAlchemy so we can use it later in our models
db = SQLAlchemy()
migrate = Migrate()

def update_config(path):
    logger.info("Validating configuration file...")
    def combine(dict1, dict2):
        for key in dict2:
            if key in dict1:
                if isinstance(dict1[key], list): # If value is a list, we want special logic
                    if isinstance(dict2[key], list): # if the "input" is a list, just do list + list
                        dict1[key] = dict1[key] + dict2[key]
                    else:
                        dict1[key].append(dict2[key])
                elif isinstance(dict1[key], dict): # calling itself recursively
                    dict1[key] = combine(dict1[key], dict2[key])
                else: # Overwrites all other values
                    dict1[key] = dict2[key]
            else: # Creates the values that doesn't exist.
                dict1[key] = dict2[key]
        return dict1

    from .constants import DEFAULT_CONFIG
    if not path.exists():
        path.write_text(json.dumps(DEFAULT_CONFIG, indent=2))

    with open(path, 'r+') as configfile:
        try:
            current = json.load(configfile)
        except:
            logger.error(f"Invalid config.json file at {str(path)}, exiting...")
            sys.exit()
        updated = combine(DEFAULT_CONFIG, current)
        path.write_text(json.dumps(updated, indent=2))
        configfile.close()

def create_app(init_schedule=False):
    app = Flask(__name__, static_url_path='', static_folder='build', template_folder='build')
    CORS(app, supports_credentials=True)
    if 'DATA_DIRECTORY' not in os.environ:
        raise Exception("DATA_DIRECTORY not found in environment")

    app.config['ENVIRONMENT'] = os.getenv('ENVIRONMENT')
    app.config['DOMAIN'] = os.getenv('DOMAIN')
    app.config['THUMBNAIL_VIDEO_LOCATION'] = int(os.getenv('THUMBNAIL_VIDEO_LOCATION') or 0)
    app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', secrets.token_hex(32)) 
    app.config['DATA_DIRECTORY'] = os.getenv('DATA_DIRECTORY')
    app.config['VIDEO_DIRECTORY'] = os.getenv('VIDEO_DIRECTORY')
    app.config['PROCESSED_DIRECTORY'] = os.getenv('PROCESSED_DIRECTORY')
    app.config['ADMIN_USERNAME'] = os.getenv('ADMIN_USERNAME')
    app.config['ADMIN_PASSWORD'] = os.getenv('ADMIN_PASSWORD')
    app.config['DISABLE_ADMINCREATE'] = bool(os.getenv("DISABLE_ADMINCREATE"))
    app.config['LDAP_ENABLE'] = bool(os.getenv("LDAP_ENABLE"))
    app.config['LDAP_URL'] = os.getenv("LDAP_URL")
    app.config['LDAP_STARTLS'] = bool(os.getenv("LDAP_STARTLS"))
    app.config['LDAP_BASEDN'] = os.getenv("LDAP_BASEDN")
    app.config['LDAP_BINDDN'] = os.getenv("LDAP_BINDDN")
    app.config['LDAP_PASSWORD'] = os.getenv("LDAP_PASSWORD")
    app.config['LDAP_USER_FILTER'] = os.getenv("LDAP_USER_FILTER")
    app.config['LDAP_ADMIN_GROUP'] = os.getenv("LDAP_ADMIN_GROUP")
    app.config['ENABLE_TRANSCODING'] = os.getenv('ENABLE_TRANSCODING', '').lower() in ('true', '1', 'yes')
    app.config['TRANSCODE_GPU'] = os.getenv('TRANSCODE_GPU', '').lower() in ('true', '1', 'yes')
    app.config['TRANSCODE_TIMEOUT'] = int(os.getenv('TRANSCODE_TIMEOUT', '7200'))  # Default: 2 hours

    app.config['SQLALCHEMY_DATABASE_URI'] = f'sqlite:///{app.config["DATA_DIRECTORY"]}/db.sqlite'
    app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
    # Configure SQLite connection for better concurrency handling
    # NullPool disables connection pooling - each request gets a fresh connection
    # This prevents stale connection issues and lock contention with SQLite
    app.config['SQLALCHEMY_ENGINE_OPTIONS'] = {
        'poolclass': NullPool,  # Disable connection pooling for SQLite
        'connect_args': {
            'timeout': 30,  # Connection timeout in seconds (wait for locks)
            'check_same_thread': False,  # Allow multi-threaded access (safe with WAL mode)
        },
    }
    app.config['SCHEDULED_JOBS_DATABASE_URI'] = f'sqlite:///{app.config["DATA_DIRECTORY"]}/jobs.sqlite'
    app.config['INIT_SCHEDULE'] = init_schedule
    app.config['MINUTES_BETWEEN_VIDEO_SCANS'] = int(os.getenv('MINUTES_BETWEEN_VIDEO_SCANS', '5'))
    app.config['WARNINGS'] = []

    if (app.config['ADMIN_PASSWORD'] and app.config['ADMIN_USERNAME'] == "admin") and app.config["DISABLE_ADMINCREATE"] == False:
        stdPasswordWarning = "You are using the Default Login-Credentials, please consider changing it."
        app.config['WARNINGS'].append(stdPasswordWarning)
        logger.warning(stdPasswordWarning)

    # Check for SteamGridDB API key
    config_path = Path(app.config['DATA_DIRECTORY']) / 'config.json'
    steamgrid_api_key = os.environ.get('STEAMGRIDDB_API_KEY', '')
    if config_path.exists():
        with open(config_path, 'r') as configfile:
            try:
                config_data = json.load(configfile)
                config_steamgrid_key = config_data.get('integrations', {}).get('steamgriddb_api_key', '')
                if config_steamgrid_key:
                    steamgrid_api_key = config_steamgrid_key
            except:
                pass

    if not steamgrid_api_key:
        steamgridWarning = "SteamGridDB API key not configured. Game metadata features are unavailable. Click here to set it up."
        app.config['WARNINGS'].append(steamgridWarning)
        logger.warning(steamgridWarning)

    paths = {
        'data': Path(app.config['DATA_DIRECTORY']),
        'video': Path(app.config['VIDEO_DIRECTORY']),
        'processed': Path(app.config['PROCESSED_DIRECTORY']),
    }
    app.config['PATHS'] = paths
    for k, path in paths.items():
        if not path.is_dir():
            logger.info(f"Creating {k} directory at {str(path)}")
            path.mkdir(parents=True, exist_ok=True)
    subpaths = [
        paths['processed'] / 'video_links',
        paths['processed'] / 'derived',
    ]
    for subpath in subpaths:
        if not subpath.is_dir():
            logger.info(f"Creating subpath directory at {str(subpath.absolute())}")
            subpath.mkdir(parents=True, exist_ok=True)

    # Ensure game_assets directory exists
    game_assets_dir = paths['data'] / 'game_assets'
    if not game_assets_dir.is_dir():
        logger.info(f"Creating game_assets directory at {str(game_assets_dir.absolute())}")
        game_assets_dir.mkdir(parents=True, exist_ok=True)

    update_config(paths['data'] / 'config.json')

    db.init_app(app)
    migrate.init_app(app, db)


    if app.config["LDAP_ENABLE"]:
        if not app.config["LDAP_URL"] or not app.config["LDAP_BINDDN"] or not app.config["LDAP_BASEDN"] or not app.config["LDAP_USER_FILTER"]:
            app.logger.error("Missing parameters for LDAP")
            exit(1)
        app.ldap_conn = ldap.initialize(app.config["LDAP_URL"])
        app.ldap_conn.protocol_version = ldap.VERSION3
        app.ldap_conn.simple_bind_s(app.config["LDAP_BINDDN"] + "," + app.config["LDAP_BASEDN"], app.config["LDAP_PASSWORD"])
        app.logger.info("LDAP connection successful")
    
    login_manager = LoginManager()
    login_manager.init_app(app)

    from .models import User

    @login_manager.user_loader
    def load_user(user_id):
        return User.query.get(int(user_id))

    # blueprint for auth routes in our app
    from .auth import auth as auth_blueprint
    app.register_blueprint(auth_blueprint)

    # blueprint for api routes
    from .api import api as api_blueprint
    app.register_blueprint(api_blueprint)

    # blueprint for non-auth parts of app
    from .main import main as main_blueprint
    app.register_blueprint(main_blueprint)

    if init_schedule:
        from .schedule import init_schedule
        init_schedule(app.config['SCHEDULED_JOBS_DATABASE_URI'],
            app.config['MINUTES_BETWEEN_VIDEO_SCANS'])

    with app.app_context():
        # db.create_all()

        # Auto-migrate: add last_seen_version column to user table if missing
        from sqlalchemy import inspect, text
        inspector = inspect(db.engine)
        user_columns = [col['name'] for col in inspector.get_columns('user')]
        if 'last_seen_version' not in user_columns:
            logger.info("Adding last_seen_version column to user table")
            db.session.execute(text('ALTER TABLE user ADD COLUMN last_seen_version VARCHAR(32)'))
            db.session.commit()

        return app
